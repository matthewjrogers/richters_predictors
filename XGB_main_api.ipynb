{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, StackingClassifier\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from bayes_opt import BayesianOptimization\n",
    "\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import category_encoders as ce\n",
    "\n",
    "#from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "train_values = pd.read_csv('train_values.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "train_values = train_values.applymap(lambda col: np.nan if col == 995 else col)\n",
    "\n",
    "drop_vars = ['building_id',\n",
    "             'has_superstructure_bamboo',                \n",
    "             'has_superstructure_mud_mortar_brick',       \n",
    "             'has_superstructure_adobe_mud',              \n",
    "             'legal_ownership_status',                    \n",
    "             'has_secondary_use',                         \n",
    "             'has_superstructure_stone_flag',             \n",
    "             'has_superstructure_rc_non_engineered',      \n",
    "             'has_superstructure_rc_engineered',          \n",
    "             'has_secondary_use_agriculture',             \n",
    "             'has_superstructure_cement_mortar_stone',    \n",
    "             'has_secondary_use_hotel',                   \n",
    "             'has_superstructure_other',                \n",
    "             'has_secondary_use_rental',                  \n",
    "             'has_secondary_use_other',                   \n",
    "             'has_secondary_use_industry',               \n",
    "             'has_secondary_use_institution',             \n",
    "             'has_secondary_use_school',                  \n",
    "             'has_secondary_use_health_post',            \n",
    "             'has_secondary_use_gov_office',          \n",
    "             'has_secondary_use_use_police' ]\n",
    "\n",
    "\n",
    "train_values = train_values.drop(drop_vars, axis = 1)\n",
    "\n",
    "targ_enc = ce.TargetEncoder()\n",
    "targ_enc.fit(train_values, train_labels['damage_grade'])\n",
    "train_values = targ_enc.transform(train_values)\n",
    "\n",
    "imp = IterativeImputer(max_iter=20, min_value = 0)\n",
    "imp.fit(train_values)\n",
    "\n",
    "train_values = pd.DataFrame(imp.transform(train_values), columns = train_values.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_full = xgb.DMatrix(train_values, train_labels['damage_grade'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 23456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'objective': 'multi:softmax',\n",
    "              'gamma': 0.001369048068388758,\n",
    "              'eta': 0.11,\n",
    "              'max_depth': 20,\n",
    "              'min_child_weight': 9,\n",
    "              'num_class' : 4,\n",
    "              'subsample' : .85,\n",
    "              'colsample_bytree' : .9,\n",
    "              'seed':23456\n",
    " }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "boost_rounds = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(train_values, train_labels.damage_grade):\n",
    "    \n",
    "    #smote = SMOTETomek(sampling_strategy = {1 : 30000}, random_state = 23456)\n",
    "    #X, y = smote.fit_resample(train_values.iloc[train_idx], train_labels.iloc[train_idx, 1])\n",
    "    \n",
    "    #dtrain = xgb.DMatrix(X, y)\n",
    "    dtrain = dtrain_full.slice(train_idx)\n",
    "    dtest  = dtrain_full.slice(test_idx)\n",
    "    \n",
    "    model = xgb.train(xgb_params,\n",
    "                      dtrain,\n",
    "                      num_boost_round = 999,\n",
    "                      evals = [(dtest, 'test_set')],\n",
    "                      early_stopping_rounds = 10,\n",
    "                      verbose_eval = False\n",
    "                  )\n",
    "    boost_rounds.append(model.best_iteration + 1)\n",
    "    print(\"Boost Rounds: {}\".format(model.best_iteration + 1))\n",
    "    boost_round = model.best_iteration + 1\n",
    "    \n",
    "    best_model = xgb.train(xgb_params,\n",
    "                      dtrain,\n",
    "                      num_boost_round = boost_round,\n",
    "                      #evals = [(dtest, 'test_set')],\n",
    "                      #early_stopping_rounds = 10,\n",
    "                      verbose_eval = False\n",
    "                  ) \n",
    "    preds = best_model.predict(dtest)\n",
    "    \n",
    "    print('F1: {}'.format(f1_score(dtest.get_label(), preds, average = 'micro')))\n",
    "    f1_scores.append(f1_score(dtest.get_label(), preds, average = 'micro'))\n",
    "\n",
    "print(f1_scores)\n",
    "print(\"Mean F1: {}\".format(np.mean(f1_scores)))\n",
    "print(\"Mean Boost Rounds: {}\".format(np.mean(boost_rounds)))\n",
    "# score to beat\n",
    "#Mean F1: 0.743968746612887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean F1: 0.7451467927006086\n",
    "Mean Boost Rounds: 113.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_values.csv')\n",
    "mtest = test.drop(drop_vars, axis = 1)\n",
    "mtest = targ_enc.transform(mtest)\n",
    "mtest = pd.DataFrame(imp.transform(mtest), columns = mtest.columns)\n",
    "dtest = xgb.DMatrix(mtest)\n",
    "\n",
    "votes_df = pd.DataFrame(test.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [23456, 45678, 56789, 12345, 98765, 87654, 76543, 54321, 13579, 246801, 57911, 791113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1\n",
      "Training model 2\n",
      "Training model 3\n",
      "Training model 4\n",
      "Training model 5\n",
      "Training model 6\n",
      "Training model 7\n",
      "Training model 8\n",
      "Training model 9\n",
      "Training model 10\n",
      "Training model 11\n",
      "Training model 12\n"
     ]
    }
   ],
   "source": [
    "for idx, seed in enumerate(seeds):\n",
    "    print(\"Training model {}\".format(idx + 1))\n",
    "    \n",
    "    xgb_params = {'objective': 'multi:softmax',\n",
    "                  'gamma': 0.001369048068388758,\n",
    "                  'eta': 0.11,\n",
    "                  'max_depth': 20,\n",
    "                  'min_child_weight': 9,\n",
    "                  'num_class' : 4,\n",
    "                  'subsample' : .85,\n",
    "                  'colsample_bytree' : .9,\n",
    "                  'seed': seed\n",
    "                 }\n",
    "    \n",
    "    boost_rounds = []\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(train_values, train_labels.damage_grade):\n",
    "            dtrain = dtrain_full.slice(train_idx)\n",
    "            dtest_part  = dtrain_full.slice(test_idx)\n",
    "            \n",
    "            model = xgb.train(xgb_params,\n",
    "                              dtrain,\n",
    "                              num_boost_round = 999,\n",
    "                              evals = [(dtest_part, 'test_set')],\n",
    "                              early_stopping_rounds = 10,\n",
    "                              verbose_eval = False\n",
    "                          )\n",
    "            \n",
    "            boost_rounds.append(model.best_iteration + 1)\n",
    "    \n",
    "    best_model = xgb.train(xgb_params,\n",
    "                           dtrain_full,\n",
    "                           num_boost_round = np.round(np.mean(boost_rounds)).astype(int),\n",
    "                           verbose_eval = False\n",
    "                           ) \n",
    "    \n",
    "    col_nam = [\"model\", str(idx + 1)]\n",
    "    col_nam = \"_\".join(col_nam)\n",
    "    \n",
    "    votes_df[col_nam] = best_model.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_df['damage_grade'] = votes_df.mode(axis = 1).iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_df[\"damage_grade\"] = votes_df[\"damage_grade\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_df[['building_id', 'damage_grade']].to_csv(\"voting_xgboost_model.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = xgb.train(xgb_params, dtrain_full, num_boost_round = np.round(np.mean(boost_rounds)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test[\"damage_grade\"] = best_model.predict(dtest)\n",
    "test[\"damage_grade\"] = test[\"damage_grade\"].astype(int)\n",
    "print(test.value_counts('damage_grade')) # check that preds look ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['building_id', 'damage_grade']].to_csv(\"xgb_model_max_depth_20.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04944899689177734"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "175/3539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
